{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhweT+KzoaHBrL61CV2ARO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ganesh-Kdt/Assignment-2-NN/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataset.csv')\n",
        "df.head()\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oezu_cOQ7L8M",
        "outputId": "b742fa5d-6162-4e8d-f323-bd35e63337cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(766, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "\n",
        "# Step 1: Analyze the dataset, returning main statistics\n",
        "dataset_statistics = df.describe()\n",
        "\n",
        "# Step 1: Check for invalid entries in each column\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    invalid_entries = [value for value in unique_values if not isinstance(value, (int, float))]\n",
        "    print(f\"Invalid entries in column '{column}': {invalid_entries}\")\n",
        "\n",
        "# Replacing invalid characters with NaN\n",
        "df_cleaned = df.replace({'f1': {'c': np.nan}, 'f2': {'f': np.nan}, 'f4': {'a': np.nan}, 'f6': {'e': np.nan, 'd': np.nan}})\n",
        "\n",
        "# Converting columns to numeric, any remaining invalid values will become NaN\n",
        "df_cleaned = df_cleaned.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Replacing NaN values with the median of their respective columns\n",
        "for column in df_cleaned.columns:\n",
        "    if df_cleaned[column].isna().any():\n",
        "        df_cleaned[column] = df_cleaned[column].fillna(df_cleaned[column].median())\n",
        "\n",
        "# Display the cleaned dataset to verify that invalid values are replaced\n",
        "print(df_cleaned.head())\n",
        "\n",
        "# Step 2: Preprocessing (Scaling and Splitting)\n",
        "\n",
        "# Separating features and target\n",
        "X = df_cleaned.drop(columns=['target'])  # Drop the target column\n",
        "y = df_cleaned['target']  # Store the target column\n",
        "\n",
        "# Scaling the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into 70% training, 15% validation, 15% testing\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "# Step 3: Converting the datasets into PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "# Display the shape of the tensors to verify the splits\n",
        "print(\"Training data shape:\", X_train_tensor.shape, y_train_tensor.shape)\n",
        "print(\"Validation data shape:\", X_val_tensor.shape, y_val_tensor.shape)\n",
        "print(\"Test data shape:\", X_test_tensor.shape, y_test_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XcHAsPZ9NkH",
        "outputId": "06eca191-e53b-4a2e-ba56-92f7b7509d57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid entries in column 'f1': ['6', '1', '8', '0', '5', '3', '10', '2', '4', '7', '9', '11', '13', '15', '17', '12', '14', 'c']\n",
            "Invalid entries in column 'f2': ['148', '85', '183', '89', '137', '116', '78', '115', '197', '125', '110', '168', '139', '189', '166', '100', '118', '107', '103', '126', '99', '196', '119', '143', '147', '97', '145', '117', '109', '158', '88', '92', '122', '138', '102', '90', '111', '180', '133', '106', '171', '159', '146', '71', '105', '101', '176', '150', '73', '187', '84', '44', '141', '114', '95', '129', '79', '0', '62', '131', '112', '113', '74', '83', '136', '80', '123', '81', '134', '142', '144', '93', '163', '151', '96', '155', '76', '160', '124', '162', '132', '120', '173', '170', '128', '108', '154', '57', '156', '153', '188', '152', '104', '87', '75', '179', '130', '194', '181', '135', '184', '140', '177', '164', '91', '165', '86', '193', '191', '161', '167', '77', '182', '157', '178', '61', '98', '127', '82', '72', '172', '94', '175', '195', '68', '186', '198', '121', '67', '174', '199', '56', '169', '149', '65', '190', 'f']\n",
            "Invalid entries in column 'f3': [72, 66, 64, 40, 74, 50, 0, 70, 96, 92, 80, 60, 84, 30, 88, 90, 94, 76, 82, 75, 58, 78, 68, 110, 56, 62, 85, 86, 48, 44, 65, 108, 55, 122, 54, 52, 98, 104, 95, 46, 102, 100, 61, 24, 38, 106, 114]\n",
            "Invalid entries in column 'f4': ['35', '29', '0', '23', '32', '45', '19', '47', '38', '30', '41', '33', '26', '15', '36', '11', '31', '37', '42', '25', '18', '24', '39', '27', '21', '34', '10', '60', '13', '20', '22', '28', '54', '40', '51', '56', '14', '17', '50', '44', '12', '46', '16', '7', '52', '43', '48', '8', '49', '63', '99', 'a']\n",
            "Invalid entries in column 'f5': ['0', '94', '168', '88', '543', '846', '175', '230', '83', '96', '235', '146', '115', '140', '110', '245', '54', '192', '207', '70', '240', '82', '36', '23', '300', '342', '304', '142', '128', '38', '100', '90', '270', '71', '125', '176', '48', '64', '228', '76', '220', '40', '152', '18', '135', '495', '37', '51', '99', '145', '225', '49', '50', '92', '325', '63', '284', '119', '204', '155', '485', '53', '114', '105', '285', '156', '78', '130', '55', '58', '160', '210', '318', '44', '190', '280', '87', '271', '129', '120', '478', '56', '32', '744', '370', '45', '194', '680', '402', '258', '375', '150', '67', '57', '116', '278', '122', '545', '75', '74', '182', '360', '215', '184', '42', '132', '148', '180', '205', '85', '231', '29', '68', '52', '255', '171', '73', '108', '43', '167', '249', '293', '66', '465', '89', '158', '84', '72', '59', '81', '196', '415', '275', '165', '579', '310', '61', '474', '170', '277', '60', '14', '95', '237', '191', '328', '250', '480', '265', '193', '79', '86', '326', '188', '106', '65', '166', '274', '77', '126', '330', '600', '185', '25', '41', '272', '321', '144', '15', '183', '91', '46', '440', '159', '540', '200', '335', '387', '22', '291', '392', '178', '127', '510', 'b', '112']\n",
            "Invalid entries in column 'f6': ['33.6', '26.6', '23.3', '28.1', '43.1', '25.6', '31', '35.3', '30.5', '0', '37.6', '38', '27.1', '30.1', '25.8', '30', '45.8', '29.6', '43.3', '34.6', '39.3', '35.4', '39.8', '29', '36.6', '31.1', '39.4', '23.2', '22.2', '34.1', '36', '31.6', '24.8', '19.9', '27.6', '24', '33.2', '32.9', '38.2', '37.1', '34', '40.2', '22.7', '45.4', '27.4', '42', '29.7', '28', '39.1', '19.4', '24.2', '24.4', '33.7', '34.7', '23', '37.7', '46.8', '40.5', '41.5', '25', '25.4', '32.8', '32.5', '42.7', '19.6', '28.9', '28.6', '43.4', '35.1', '32', '24.7', '32.6', '43.2', '22.4', '29.3', '24.6', '48.8', '32.4', '38.5', '26.5', '19.1', '46.7', '23.8', '33.9', '20.4', '28.7', '49.7', '39', '26.1', '22.5', '39.6', '29.5', '34.3', '37.4', '33.3', '31.2', '28.2', '53.2', '34.2', '26.8', '55', '42.9', '34.5', '27.9', '38.3', '21.1', '33.8', '30.8', '36.9', '39.5', '27.3', '21.9', '40.6', '47.9', '50', '25.2', '40.9', '37.2', '44.2', '29.9', '31.9', '28.4', '43.5', '32.7', '67.1', '45', '34.9', '27.7', '35.9', '22.6', '33.1', '30.4', '52.3', '24.3', '22.9', '34.8', '30.9', '40.1', '23.9', '37.5', '35.5', '42.8', '42.6', '41.8', '35.8', '37.8', '28.8', '23.6', '35.7', '36.7', '45.2', '44', '46.2', '35', '43.6', '44.1', '18.4', '29.2', '25.9', '32.1', '36.3', '40', '25.1', '27.5', '45.6', '27.8', '24.9', '25.3', '37.9', '27', '26', '38.7', '20.8', '36.1', '30.7', '32.3', '52.9', '21', '39.7', '25.5', '26.2', '19.3', '38.1', '23.5', '45.5', '23.1', '39.9', '36.8', '21.8', '41', '42.2', '34.4', '27.2', '36.5', '29.8', '39.2', '38.4', '36.2', '48.3', '20', '22.3', '45.7', '23.7', '22.1', '42.1', '42.4', '18.2', '26.4', '45.3', '37', '24.5', '32.2', '59.4', '21.2', '26.7', '30.2', '46.1', '41.3', '38.8', '35.2', '42.3', '40.7', '46.5', '33.5', '37.3', '30.3', '26.3', '21.7', '36.4', '28.5', '26.9', '38.6', '31.3', '19.5', '20.1', '40.8', '23.4', '28.3', '38.9', '57.3', '35.6', '49.6', '44.6', '24.1', '44.5', '41.2', '49.3', '46.3', 'd']\n",
            "Invalid entries in column 'f7': ['0.627', '0.351', '0.672', '0.167', '2.288', '0.201', '0.248', '0.134', '0.158', '0.232', '0.191', '0.537', '1.441', '0.398', '0.587', '0.484', '0.551', '0.254', '0.183', '0.529', '0.704', '0.388', '0.451', '0.263', '0.205', '0.257', '0.487', '0.245', '0.337', '0.546', '0.851', '0.267', '0.188', '0.512', '0.966', '0.42', '0.665', '0.503', '1.39', '0.271', '0.696', '0.235', '0.721', '0.294', '1.893', '0.564', '0.586', '0.344', '0.305', '0.491', '0.526', '0.342', '0.467', '0.718', '0.962', '1.781', '0.173', '0.304', '0.27', '0.699', '0.258', '0.203', '0.855', '0.845', '0.334', '0.189', '0.867', '0.411', '0.583', '0.231', '0.396', '0.14', '0.391', '0.37', '0.307', '0.102', '0.767', '0.237', '0.227', '0.698', '0.178', '0.324', '0.153', '0.165', '0.443', '0.261', '0.277', '0.761', '0.255', '0.13', '0.323', '0.356', '0.325', '1.222', '0.179', '0.262', '0.283', '0.93', '0.801', '0.207', '0.287', '0.336', '0.247', '0.199', '0.543', '0.192', '0.588', '0.539', '0.22', '0.654', '0.223', '0.759', '0.26', '0.404', '0.186', '0.278', '0.496', '0.452', '0.403', '0.741', '0.361', '1.114', '0.457', '0.647', '0.088', '0.597', '0.532', '0.703', '0.159', '0.268', '0.286', '0.318', '0.272', '0.572', '0.096', '1.4', '0.218', '0.085', '0.399', '0.432', '1.189', '0.687', '0.137', '0.637', '0.833', '0.229', '0.817', '0.204', '0.368', '0.743', '0.722', '0.256', '0.709', '0.471', '0.495', '0.18', '0.542', '0.773', '0.678', '0.719', '0.382', '0.319', '0.19', '0.956', '0.084', '0.725', '0.299', '0.244', '0.745', '0.615', '1.321', '0.64', '0.142', '0.374', '0.383', '0.578', '0.136', '0.395', '0.187', '0.905', '0.15', '0.874', '0.236', '0.787', '0.407', '0.605', '0.151', '0.289', '0.355', '0.29', '0.375', '0.164', '0.431', '0.742', '0.514', '0.464', '1.224', '1.072', '0.805', '0.209', '0.666', '0.101', '0.198', '0.652', '2.329', '0.089', '0.645', '0.238', '0.394', '0.293', '0.479', '0.686', '0.831', '0.582', '0.446', '0.402', '1.318', '0.329', '1.213', '0.427', '0.282', '0.143', '0.38', '0.284', '0.249', '0.926', '0.557', '0.092', '0.655', '1.353', '0.612', '0.2', '0.226', '0.997', '0.933', '1.101', '0.078', '0.24', '1.136', '0.128', '0.422', '0.251', '0.677', '0.296', '0.454', '0.744', '0.881', '0.28', '0.259', '0.619', '0.808', '0.34', '0.434', '0.757', '0.613', '0.692', '0.52', '0.412', '0.84', '0.839', '0.156', '0.215', '0.326', '1.391', '0.875', '0.313', '0.433', '0.626', '1.127', '0.315', '0.345', '0.129', '0.527', '0.197', '0.731', '0.148', '0.123', '0.127', '0.122', '1.476', '0.166', '0.932', '0.343', '0.893', '0.331', '0.472', '0.673', '0.389', '0.485', '0.349', '0.279', '0.346', '0.252', '0.243', '0.58', '0.559', '0.302', '0.569', '0.378', '0.385', '0.499', '0.306', '0.234', '2.137', '1.731', '0.545', '0.225', '0.816', '0.528', '0.509', '1.021', '0.821', '0.947', '1.268', '0.221', '0.66', '0.239', '0.949', '0.444', '0.463', '0.803', '1.6', '0.944', '0.196', '0.241', '0.161', '0.135', '0.376', '1.191', '0.702', '0.674', '1.076', '0.534', '1.095', '0.554', '0.624', '0.219', '0.507', '0.561', '0.421', '0.516', '0.264', '0.328', '0.233', '0.108', '1.138', '0.147', '0.727', '0.435', '0.497', '0.23', '0.955', '2.42', '0.658', '0.33', '0.51', '0.285', '0.415', '0.381', '0.832', '0.498', '0.212', '0.364', '1.001', '0.46', '0.733', '0.416', '0.705', '1.022', '0.269', '0.6', '0.571', '0.607', '0.17', '0.21', '0.126', '0.711', '0.466', '0.162', '0.419', '0.63', '0.365', '0.536', '1.159', '0.629', '0.292', '0.145', '1.144', '0.174', '0.547', '0.163', '0.738', '0.314', '0.968', '0.409', '0.297', '0.525', '0.154', '0.771', '0.107', '0.493', '0.717', '0.917', '0.501', '1.251', '0.735', '0.804', '0.661', '0.549', '0.825', '0.423', '1.034', '0.16', '0.341', '0.68', '0.591', '0.3', '0.121', '0.502', '0.401', '0.601', '0.748', '0.338', '0.43', '0.892', '0.813', '0.693', '0.575', '0.371', '0.206', '0.417', '1.154', '0.925', '0.175', '1.699', '0.682', '0.194', '0.4', '0.1', '1.258', '0.482', '0.138', '0.593', '0.878', '0.157', '1.282', '0.141', '0.246', '1.698', '1.461', '0.347', '0.362', '0.393', '0.144', '0.732', '0.115', '0.465', '0.649', '0.871', '0.149', '0.695', '0.303', '0.61', '0.73', '0.447', '0.455', '0.133', '0.155', '1.162', '1.292', '0.182', '1.394', '0.217', '0.631', '0.88', '0.614', '0.332', '0.366', '0.181', '0.828', '0.335', '0.856', '0.886', '0.439', '0.253', '0.598', '0.904', '0.483', '0.565', '0.118', '0.177', '0.176', '0.295', '0.441', '0.352', '0.826', '0.97', '0.595', '0.317', '0.265', '0.646', '0.426', '0.56', '0.515', '0.453', '0.785', '0.734', '1.174', '0.488', '0.358', '1.096', '0.408', '1.182', '0.222', '1.057', 'e', '0.171']\n",
            "Invalid entries in column 'target': [1, 0]\n",
            "    f1     f2  f3    f4     f5    f6     f7  target\n",
            "0  6.0  148.0  72  35.0    0.0  33.6  0.627       1\n",
            "1  1.0   85.0  66  29.0    0.0  26.6  0.351       0\n",
            "2  8.0  183.0  64   0.0    0.0  23.3  0.672       1\n",
            "3  1.0   89.0  66  23.0   94.0  28.1  0.167       0\n",
            "4  0.0  137.0  40  35.0  168.0  43.1  2.288       1\n",
            "Training data shape: torch.Size([536, 7]) torch.Size([536])\n",
            "Validation data shape: torch.Size([115, 7]) torch.Size([115])\n",
            "Test data shape: torch.Size([115, 7]) torch.Size([115])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4HN_J1xg5ext",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f1f6bf-0b10-452f-f28b-21d1eaaab93c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.6661, Val Loss: 0.6562\n",
            "Epoch [2/50], Loss: 0.6410, Val Loss: 0.6307\n",
            "Epoch [3/50], Loss: 0.6109, Val Loss: 0.6083\n",
            "Epoch [4/50], Loss: 0.5884, Val Loss: 0.5862\n",
            "Epoch [5/50], Loss: 0.5658, Val Loss: 0.5636\n",
            "Epoch [6/50], Loss: 0.5513, Val Loss: 0.5413\n",
            "Epoch [7/50], Loss: 0.5286, Val Loss: 0.5243\n",
            "Epoch [8/50], Loss: 0.5154, Val Loss: 0.5145\n",
            "Epoch [9/50], Loss: 0.4719, Val Loss: 0.5125\n",
            "Epoch [10/50], Loss: 0.4831, Val Loss: 0.5176\n",
            "Epoch [11/50], Loss: 0.4807, Val Loss: 0.5212\n",
            "Epoch [12/50], Loss: 0.4763, Val Loss: 0.5228\n",
            "Epoch [13/50], Loss: 0.4709, Val Loss: 0.5251\n",
            "Epoch [14/50], Loss: 0.4590, Val Loss: 0.5254\n",
            "Epoch [15/50], Loss: 0.4668, Val Loss: 0.5261\n",
            "Epoch [16/50], Loss: 0.4660, Val Loss: 0.5248\n",
            "Epoch [17/50], Loss: 0.4630, Val Loss: 0.5270\n",
            "Epoch [18/50], Loss: 0.4549, Val Loss: 0.5281\n",
            "Epoch [19/50], Loss: 0.4655, Val Loss: 0.5320\n",
            "Epoch [20/50], Loss: 0.4514, Val Loss: 0.5265\n",
            "Epoch [21/50], Loss: 0.4547, Val Loss: 0.5245\n",
            "Epoch [22/50], Loss: 0.4688, Val Loss: 0.5224\n",
            "Epoch [23/50], Loss: 0.4418, Val Loss: 0.5201\n",
            "Epoch [24/50], Loss: 0.4441, Val Loss: 0.5204\n",
            "Epoch [25/50], Loss: 0.4507, Val Loss: 0.5231\n",
            "Epoch [26/50], Loss: 0.4447, Val Loss: 0.5296\n",
            "Epoch [27/50], Loss: 0.4358, Val Loss: 0.5341\n",
            "Epoch [28/50], Loss: 0.4448, Val Loss: 0.5357\n",
            "Epoch [29/50], Loss: 0.4368, Val Loss: 0.5335\n",
            "Epoch [30/50], Loss: 0.4379, Val Loss: 0.5310\n",
            "Epoch [31/50], Loss: 0.4297, Val Loss: 0.5337\n",
            "Epoch [32/50], Loss: 0.4507, Val Loss: 0.5329\n",
            "Epoch [33/50], Loss: 0.4386, Val Loss: 0.5289\n",
            "Epoch [34/50], Loss: 0.4385, Val Loss: 0.5343\n",
            "Epoch [35/50], Loss: 0.4325, Val Loss: 0.5345\n",
            "Epoch [36/50], Loss: 0.4402, Val Loss: 0.5368\n",
            "Epoch [37/50], Loss: 0.4331, Val Loss: 0.5349\n",
            "Epoch [38/50], Loss: 0.4266, Val Loss: 0.5370\n",
            "Epoch [39/50], Loss: 0.4355, Val Loss: 0.5402\n",
            "Epoch [40/50], Loss: 0.4145, Val Loss: 0.5384\n",
            "Epoch [41/50], Loss: 0.4252, Val Loss: 0.5417\n",
            "Epoch [42/50], Loss: 0.4356, Val Loss: 0.5489\n",
            "Epoch [43/50], Loss: 0.4497, Val Loss: 0.5440\n",
            "Epoch [44/50], Loss: 0.4199, Val Loss: 0.5435\n",
            "Epoch [45/50], Loss: 0.4270, Val Loss: 0.5439\n",
            "Epoch [46/50], Loss: 0.4196, Val Loss: 0.5393\n",
            "Epoch [47/50], Loss: 0.4181, Val Loss: 0.5354\n",
            "Epoch [48/50], Loss: 0.4275, Val Loss: 0.5352\n",
            "Epoch [49/50], Loss: 0.4234, Val Loss: 0.5415\n",
            "Epoch [50/50], Loss: 0.4221, Val Loss: 0.5480\n",
            "Total Training Time: 2.32 seconds\n",
            "Test Accuracy: 73.04%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Step 1: Define the Neural Network architecture\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        # Input layer\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        # Hidden layer\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        # Output layer\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()  # Binary classification output\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# Step 2: Initialize the model, loss function, and optimizer\n",
        "input_size = 7  # Number of input features (based on your dataset)\n",
        "hidden_size = 64  # Hidden layer size\n",
        "output_size = 1  # Binary classification\n",
        "\n",
        "model = SimpleNN(input_size, hidden_size, output_size)\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 3: Train the model\n",
        "epochs = 50  # Number of epochs\n",
        "batch_size = 100  # Batch size\n",
        "\n",
        "# DataLoader for batching\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs.squeeze(), labels)  # Compute loss\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in val_loader:\n",
        "            val_outputs = model(val_inputs)\n",
        "            val_loss += criterion(val_outputs.squeeze(), val_labels).item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
        "\n",
        "end_time = time.time()  # Record the end time\n",
        "training_time = end_time - start_time  # Calculate elapsed time\n",
        "print(f\"Total Training Time: {training_time:.2f} seconds\")\n",
        "\n",
        "# Step 4: Evaluate the model on the test set\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for test_inputs, test_labels in test_loader:\n",
        "        test_outputs = model(test_inputs)\n",
        "        predicted = (test_outputs.squeeze() >= 0.5).float()  # Binarize predictions\n",
        "        total += test_labels.size(0)\n",
        "        correct += (predicted == test_labels).sum().item()\n",
        "\n",
        "accuracy = correct / total * 100\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yn6vOY6D6elu"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}